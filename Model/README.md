# Model
## gpt-4o-mini
- GPT-4o-mini 是一個經過優化的小型語言模型，屬於 OpenAI 的 GPT-4 系列，設計目的是在較低的計算成本下提供高效的NLP能力，以下為gpt-4o-mini相關的技術。
  - 模型架構與參數調整
    - GPT-4o-mini 基於 GPT-4 的核心架構，進一步縮小了模型的規模，專注於資源效率與實用性。模型的參數數量減少，導致其推理速度更快，適合資源受限的場景。
  - 多模態能力的簡化
    - 雖然完整的 GPT-4 支援多模態輸入（如文本與圖像），但 GPT-4o-mini 主要專注於文本處理。這種簡化有助於降低硬體需求，同時保證核心自然語言處理能力。
    
  - 成本與性能平衡
    - GPT-4o-mini 是為需要低延遲、高效能的應用而設計，其訓練成本與運行資源比完整版本顯著降低。根據測試，它在小型到中型的應用場景中表現良好。
      
  - 而在各種能力下的gpt-4o-mini
    1. 記憶能力：針對長文本處理進行了特化，能夠有效處理中等長度的上下文。
    2. 推理效率：在處理日常任務（如文本生成、分類、摘要）時，執行速度比 GPT-4 更快，特別適合即時互動應用。
    3. 資源適配：能在中等規模的 GPU 或雲端環境中高效運行，適用於開發者和小型企業的應用需求。
       
  - GPT-4o-mini 可用於：
    客戶服務聊天機器人
    自然語言理解（如意圖分析、情感分析）
    簡單的機器翻譯和內容生成
    教育輔助工具（如回答問題或生成教學內容）。
    
- 因此我們透過gpt-4o-mini，在BM25過濾後文檔中挑選最合適的文檔作為最終答案。

## BM25
- BM25 是一種用來評估搜尋詞與文件之間相關性的演算法Q，這是一種基於機率檢索模型提出的演算法。以下用簡單的方式描述 BM25 演算法：我們有一個查詢（query）和一批文件（Ds），現在要計算查詢與每篇文件D之間的相關性分數，做法是先對查詢進行切分，取得每個詞語 q_i，然後將每個詞語的分數分為以下三部分組成：

  1. 查詢中每個詞語 q_i 與文件D之間的相關性
  2. 詞語 q_i 與查詢之間的相關性
  3. 每個詞語的重要程度（權重）
最後，將每個詞語的分數進行加總，就能得到查詢與文件之間的分數。


## 使用情況
- 其中在進行Retrieval時，用到了兩個模型，一個是BM25一個是gpt-4o-mini
- BM25使用到的是預訓練好的檢索模型，透過Library rank_bm25 import BM25Okapi，透過其來建立模型檢索相關的文檔內容
- gpt-4o-mini是透過現有的LLM，並沒有特別pre-train新的模型，而是透過API的方式直接使用外部提供的大語言模型來做更精確地檢索


# 程式說明
- 我們先是透過了BM25來檢索出與問題最相關的3個文檔內容
- 接著再透過gpt-4o-mini從3個之中挑出最相關的作為答案
